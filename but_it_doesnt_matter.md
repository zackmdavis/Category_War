"But It Doesn't Matter"

If you ever find yourself saying, "Even if Hypothesis _H_ is true, it doesn't have any decision-relevant implications," _you are rationalizing!_ The fact that _H_ is interesting enough for you to be considering the question at all (it's not some arbitrary trivium like the 1923th binary digit of π, or the low temperature in São Paulo on September 17, 1978) means that it must have some relevance to the things you care about. It is _vanishingly improbable_ that your optimal decisions are going to be the _same_ in worlds where _H_ is true and worlds where _H_ is false. The fact that you're tempted to _say_ they're the same is probably because some part of you is afraid of some of the imagined consequences of _H_ being true. But _H_ is already true or already false! If you happen to live in a world where _H_ is true, and you make decisions as if you lived in a world where _H_ is false, you are thereby missing out on all the extra utility you would get if you made the _H_-optimal decisions instead! If you can figure out exactly what you're afraid of, maybe that will help you work out what the _H_-optimal decisions are. Then you'll be a [better position to successfully notice](https://www.lesswrong.com/posts/3XgYbghWruBMrPTAL/leave-a-line-of-retreat) which world you _actually_ live in.

-----

(Publication history note: this post is lightly adapted from a 14 January 2017 Facebook status update, but Facebook isn't a good permanent home for content for [various reasons](https://thezvi.wordpress.com/2017/04/22/against-facebook/).)