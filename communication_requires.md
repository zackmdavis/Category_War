## Communication Requires Common Interests or Differential Signal Costs

> If a lion could speak, we could not understand her.
>
> —Ludwig Wittgenstein

In order for information to be transmitted from one place to another, it needs to be conveyed by some physical medium: [material links of cause and effect that vary in response to variation at the source](https://www.lesswrong.com/posts/6s3xABaXKPdFwA3FS/what-is-evidence), correlating the states of different parts of the universe—a "map" that reflects a "territory." When you see a rock, that's only possible because the pattern of light reflected from the rock into your eyes is different from what it would have been if the rock were a different color, or if it weren't there.

This is the rudimentary cognitive technology of _perception_. Notably, perception only requires technology on the receiving end. Your brain and your eyes were optimized by natural selection to be able to do things like interpreting light as conveying information from elsewhere in the universe. The rock wasn't: rocks were just the same before any animals evolved to see them. The light wasn't, either: light reflected off rocks just the same before, too.

In contrast, the advanced cognitive technology of _communication_ is more capital-intensive: not only the receiver but also the source (now called the "sender") and the medium (now called "signals") must be optimized for the task. When you read a blog post about a rock, not only did the post author need to use the technology of perception to see the rock, you and the author also needed to have a language in common, from which the author would have used different words if the rock were a different color, or if it weren't there.

Like many advanced technologies, communication is fragile and needs to be delicately maintained. A common language requires solving the coordination problem of agreeing on a convention that assigns meanings to signals—and _maintaining_ that convention through continued usage. The existence of stable solutions to the coordination problem ends up depending on the communicating agents' goals, even if the _meaning_ of the convention (should the agents succeed in establishing one) is strictly denotative. If the sender and receiver's interests are aligned, [a convention can be discovered by simple reinforcement learning from trial and error](https://www.lesswrong.com/posts/4hLcbXaqudM9wSeor/philosophy-in-the-darkest-timeline-basics-of-the-evolution). This doesn't work if the sender and receiver's interests diverge—if the sender would profit by making the receiver update in the wrong direction. [Deception is parasitic on conventional meaning](https://www.lesswrong.com/posts/YptSN8riyXJjJ8Qp8/maybe-lying-can-t-exist): it is _impossible_ for there to be a language in which most sentences were lies—because then there could be no way to learn what the "intended" meaning was. The incentive to deceive thus threatens to [snowball to undermine the preconditions for signals to refer to anything at all](https://www.lesswrong.com/posts/qDmnyEMtJkE9Wrpau/simulacra-levels-and-their-interactions).

There is, however, another way to solve the coordination problem of meaning. [If the sender pays different _costs_ for sending different signals](https://en.wikipedia.org/wiki/Signalling_theory), communication between adversaries becomes possible, using an assignment of meanings to signals that makes it _more expensive to say things when they aren't true_. If somehow granted a telegraph wire, a gazelle and a cheetah would have nothing to say to each other: any gazelle would prefer to have the language to say, "Don't tire yourself out chasing me; I'm too fast"—but precisely because _any_ gazelle would say it, no cheetah would have an incentive to learn Morse code. But if the gazelle [leaps in the air with its legs stiffened](https://en.wikipedia.org/wiki/Stotting)—higher than weak or injured gazelles could leap—then the message can be received.

Costly signals are both wasteful, and sharply limited in their expressive power: it's hard to imagine doing any complex grammar and logic under such constraints. Is this really the _only possible_ way to talk to people who aren't your friends? The situation turns out not to be nearly that bleak: [Michael Lachmann, Szabolcs Számadó, and Carl T. Bergstrom point out](https://www.pnas.org/content/98/23/13189) that maintaining a convention only requires that _departing_ from it be costly. In the extreme case, if people straight-up _died_ if they ever told a lie, then the things people _actually_ said would be true. More realistically, social sanction against liars is enough to decouple the design of signaling conventions from the enforcement mechanism that holds them in place, enabling the development of complex language. Still, this works better for the aspects of conflicting interests that are verifiable; communication on more contentious issues may fall back to costly signaling.

The fragility of communication lends plausibility to theories that attribute signaling functions to human and other animal behavior. To the novice, this seems counterintuitive and unmotivatedly cynical. "Art is signaling! Charity is signaling! Conversation is signaling!" Really? Why should anyone believe that?

The thing to remember is this: the "signal" in "virtue signal" is the _same sense of the same word_ as the "signal" in "communication signal." [Flares](https://en.wikipedia.org/wiki/Flare_gun) are distress signals: if people only fire them in an emergency, then the presence of the flare communicates the danger. In the same way, if more virtuous people are better at virtue signaling, then the presence of the signal indicates virtue. If natural selection designs creatures that both have diverging interests, and have needs to communicate with each other, then those creatures will probably have lots of adaptations for providing expensive-to-fake evidence of the information they need to communicate. That's the only way to do it!
