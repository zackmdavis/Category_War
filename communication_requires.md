## Unlike Perception, Communication Requires Common Interest or Differential Signal Costs

> If a lion could speak, we would not understand her.
>
> —Ludwig Wittgenstein

In order for information to be transmitted from one place to another, it needs to be conveyed by some physical medium: [material links of cause and effect that vary in response to variation at the source](https://www.lesswrong.com/posts/6s3xABaXKPdFwA3FS/what-is-evidence), correlating the states of different parts of the universe—a "map" that reflects a "territory." When you see a rock, that's only possible because the pattern of light reflected from the rock into your eyes is different from what it would have been if the rock were a different color, or if it weren't there.

This is the rudimentary cognitive technology of _perception_. Notably, perception only requires technology on the receiving end. Your brain and your eyes were optimized by natural selection to interpret light as conveying information from elsewhere in the universe. The rock wasn't: rocks were just the same before any animals evolved to see them. The light wasn't, either: light reflected off rocks just the same before, too.

In contrast, the advanced cognitive technology of _communication_ is more capital-intensive: not only the receiver but also the source (now called the "sender") and the medium (now called "signals") must be optimized for the task. When you read a blog post about a rock, not only did the post author need to use the technology of perception to see the rock, you and the author also needed to have a language in common, from which the author would have used different words if the rock were a different color, or if it weren't there.

A common language requires solving the coordination problem of agreeing on a convention that assigns meanings to signals. The existence of solutions to the coordination problem ends up depending on the agents' goals, even if the _meaning_ of the convention (should the agents succeed in establishing one) is strictly denotative. If the sender and receiver's interests are aligned, [a convention can be discovered by simple reinforcement learning from trial and error](https://www.lesswrong.com/posts/4hLcbXaqudM9wSeor/philosophy-in-the-darkest-timeline-basics-of-the-evolution). However, this doesn't work if the sender and receiver's interests diverge—if the sender would profit by making the receiver update in the wrong direction. [Deception is parasitic on conventional meaning](https://www.lesswrong.com/posts/YptSN8riyXJjJ8Qp8/maybe-lying-can-t-exist): it is _impossible_ for there to be a language in which most sentences were lies—because then there could be no way to learn what the "intended" meaning was.

Nevertheless, it is possible under some circumstances for adversaries to communicate. [TODO: costly signaling also solves the problem, stotting]

[TODO: the signals in equilibrium need not be costly, https://www.pnas.org/content/98/23/13189 ]

[TODO: this makes Hansonian views on the centrality of signaling to human behavior make more sense—a more honest world would be deeply alien]
