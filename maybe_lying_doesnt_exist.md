## Maybe Lying Doesn't Exist

In ["Against Lie Inflation"](https://slatestarcodex.com/2019/07/16/against-lie-inflation/), the immortal Scott Alexander argues that the word "lie" should be reserved for knowingly-made false statements, and not used in an expanded sense that includes unconscious motivated reasoning. Alexander argues that the expanded sense draws the category boundaries of "lying" too widely in a way that would make the word less useful. The hypothesis that predicts everything predicts nothing: in order for "Kevin lied" to _mean something_, some possible states-of-affairs need to be identified as _not_ lying, so that the statement "Kevin lied" can correspond to [redistributing conserved probability mass](http://yudkowsky.net/rational/technical/) _away from_ "not lying" states-of-affairs _onto_ "lying" states-of-affairs.

All of this is entirely correct. But Jessica Taylor (whose post ["The AI Timelines Scam"](https://unstableontology.com/2019/07/11/the-ai-timelines-scam/) inspired "Against Lie Inflation") wasn't arguing that _everything_ is lying; she was just using a _more_ permissive conception of lying than the one Alexander prefers, such that Alexander didn't think that Taylor's definition could stably and consistently identify non-lies.

Concerning Alexander's arguments against the expanded definition, I find I have one strong objection (that appeal-to-consequences is an invalid form of reasoning for optimal-categorization questions for essentially the same reason as it is for questions of simple fact), and one more speculative objection (that our intuitive "folk theory" of lying may actually be empirically mistaken). Let me explain.

(A small clarification: for myself, I _also_ tend to frown on the expanded sense of "lying". But the _reasons_ for frowning matter! People who superficially agree on a conclusion but for _different reasons_, are [not really on the same page](https://www.lesswrong.com/posts/n4ukoQzkgbAqpzqb5/argue-politics-with-your-best-friends)!)

### Appeals to Consequences Are Invalid

> There is no method of reasoning more common, and yet none more blameable, than, in philosophical disputes, to endeavour the refutation of any hypothesis, by a pretense of its dangerous consequences[.]
>
> —[David Hume](https://www.bartleby.com/37/3/12.html)

Alexander contrasts the imagined consequences of the expanded definition of "lying" becoming more widely accepted, to a world that uses the restricted definition:

> [E]veryone is much angrier. In the restricted-definition world, a few people write posts suggesting that there may be biases affecting the situation. In the expanded-definition world, those same people write posts accusing the other side of being liars perpetrating a fraud. I am willing to listen to people suggesting I might be biased, but if someone calls me a liar I'm going to be pretty angry and go into defensive mode. I'll be less likely to hear them out and adjust my beliefs, and more likely to try to attack them.

But this is an [appeal to consequences](https://en.wikipedia.org/wiki/Appeal_to_consequences). [Appeals to consequences](https://www.lesswrong.com/posts/P3FQNvnW8Cz42QBuA/dialogue-on-appeals-to-consequences) are invalid because they represent a map–territory confusion, an attempt to optimize our _description_ of reality at the expense of our ability to describe reality _accurately_ (which we need in order to _actually_ optimize reality).

(Again, the appeal is still invalid even if the conclusion—in this case, that unconscious rationalization shouldn't count as "lying"—might be true for _other reasons_.)

Some aspiring epistemic rationalists like to call this the ["Litany of Tarski"](https://wiki.lesswrong.com/wiki/Litany_of_Tarski). _If_ Elijah is lying (with respect to whatever the [optimal category boundary](https://www.lesswrong.com/posts/esRZaPXSHgWzyB2NL/where-to-draw-the-boundaries) for "lying" turns out to be according to [our standard Bayesian philosophy of language](https://www.lesswrong.com/posts/FaJaCgqBKphrDzDSj/37-ways-that-words-can-be-wrong)), _then_ I desire to believe that Elijah is lying (with respect to the optimal category boundary according to ... _&c._). _If_ Elijah is _not_ lying (with respect to ... _&c._), _then_ I desire to believe that Elijah is _not_ lying.

If the one comes to me and says, "Elijah is not lying; to support this claim, I offer this-and-such evidence of his sincerity," then this is right and proper, and I am eager to examine the evidence presented.

If the one comes to me and says, "You should choose to define _lying_ such that Elijah is not lying, because if you said that he was lying, then he might feel angry and defensive," this is _insane_. The map is not the territory! If Elijah's behavior is, _in fact_, deceptive—if he says things that cause people who trust him to be worse at [anticipating their experiences](https://www.lesswrong.com/posts/a7n8GdKiAZRX86T5A/making-beliefs-pay-rent-in-anticipated-experiences) when he reasonably [could](https://www.lesswrong.com/posts/3buXtNiSK8gcRLMSG/possibility-and-could-ness) have avoided this—I can't make his behavior not-deceptive by _changing the meanings of words_.

Now, I _agree_ that it might very well empirically be the case that if I _say_ that Elijah is lying (where Elijah can hear me), he might get angry and defensive, which could have a variety of negative social consequences. But that's not an argument for changing the definition of lying; that's an argument that I have an incentive to lie about whether I think Elijah is lying! (Though [Glomarizing](https://www.lesswrong.com/posts/xdwbX9pFEr7Pomaxv/meta-honesty-firming-up-honesty-around-its-edge-cases#1__Glomarization_can_t_practically_cover_many_cases_) about whether I think he's lying might be an even better play.)

Alexander is concerned that people might strategically equivocate between different definitions of "lying" as an unjust social attack against the innocent, using the classic [motte-and-bailey](https://slatestarcodex.com/2014/11/03/all-in-all-another-brick-in-the-motte/) maneuver: first, argue that someone is "lying (expanded definition)" (the motte), then switch to treating them as if they were guilty of "lying (restricted definition)" (the bailey) and hope no one notices.

So, I agree that [this is a very real problem](https://www.lesswrong.com/posts/shoMpaoZypfkXv84Y/variable-question-fallacies). But it's worth noting that the problem of equivocation between [different category boundaries associated with the same word](https://www.lesswrong.com/posts/4FcxgdvdQP45D6Skg/disguised-queries) applies _symmetrically_: if it's possible to use an expanded definition of a socially-disapproved category as the motte and a restricted definition as the bailey in an unjust attack against the innocent, then it's _also_ possible to use an expanded definition as the bailey and a restricted definition as the motte in an unjust defense of the guilty.

Alexander writes:

> The whole reason that rebranding lesser sins as "lying" is tempting is because everyone knows "lying" refers to something very bad. 

Right—and conversely, because everyone knows that "lying" refers to something very bad, it's tempting to rebrand lies as lesser sins. Ruby Bloom [explains what this looks like in the wild](https://www.lesswrong.com/posts/QB9eXzzQWBhq9YuB8/rationalizing-and-sitting-bolt-upright-in-alarm#R9kEwAz8YbQTWGPsB):

> I worked in a workplace where lying was commonplace, conscious, and system 2. Clients asking if we could do something were told "yes, we've already got that feature (we hadn't) and we already have several clients successfully using that (we hadn't)." Others were invited to be part an "existing beta program" alongside others just like them (in fact, they would have been the very first). When I objected, I was told "no one wants to be the first, so you have to say that."
>
> [...] I think they lie to themselves that they're not lying (so that if you search their thoughts, they never think "I'm lying")[.]

If your interest in the philosophy of language is primarily to _avoid being blamed for things_—perhaps because you percieve that you live [in a Hobbesian dystopia](https://www.lesswrong.com/posts/YRgMCXMbkKBZgMz4M/asymmetric-justice#puGDkhWCcaNJEMkdz) where the primary function of words is to elicit actions, where the [denotative structure](https://www.lesswrong.com/posts/i2bWqSFgyFxowTKWE/actors-and-scribes-words-and-deeds) of language has [decayed](https://www.lesswrong.com/posts/8XDZjfThxDxLvKWiM/excerpts-from-a-larger-discussion-about-simulacra) long ago, and all that's left is a [standardized list of approved attacks](https://www.lesswrong.com/posts/r2dTchodfqX4o5DYH/blame-games)—in that case, it makes perfect sense to worry about "lie inflation" but not about "lie deflation." If describing something as "lying" is primarily a weapon, then applying extra scrutiny to uses of that weapon is a wise arms-restriction treaty.

But if your interest in the philosophy of language is to improve and refine the uniquely human power of [vibratory telepathy](https://www.lesswrong.com/posts/SXK87NgEPszhWkvQm/mundane-magic)—to construct shared maps that reflect the territory—if you're interested in revealing what kinds of deception are _actually happening_, and why—

(in short, if you are an aspiring epistemic rationalist)

—then the asymmetrical fear of false-positive identifications of "lying" but not false-negatives—along with the focus on "bad actors", "stigmatization", "attacks", _&c._—just looks _weird_. What does _that_ have to do with maximizing the probability you assign to the right answer??

[TODO: address stabilizing Schelling point objection]  
[TODO: maybe everyone _should_ be angrier, if lies are actualy that common and anger is a functional response?]  
[TODO: acknowledge that Alexander must know that the reason to "prefer" a category is _because_ it affects anticipations—"its web of connotations in our minds"]

### The Optimal Categorization Depends on the Actual Psychology of Deception

> _Deception_  
> _My life seems like it's nothing but_  
> _Deception_  
> _A big charade_  
>
> _I never meant to lie to you_  
> _I swear it_  
> _I never meant to play those games_
>
> —["Deception"](https://www.youtube.com/watch?v=kQKs0eQHZRs) by Jem and the Holograms

Okay, if the fear of rhetorical warfare isn't a legitimate reason to avoid calling things lies, we're still left with the obvious objection that "lying" is a _different thing_ from "rationalizing" or "being biased". Everyone is biased in some way or another, but to _lie_ is ["[t]o give false information intentionally with intent to deceive."](https://en.wiktionary.org/wiki/lie#Etymology_2)

Sometimes it might make sense to use the word "lie" in [noncentral](https://www.lesswrong.com/posts/yCWPkLi8wJvewPbEp/the-noncentral-fallacy-the-worst-argument-in-the-world) sense—as when we speak of "lying to oneself" or "oops, I lied" (in reaction to being corrected)

As Alexander says, conflating the two can only be to the benefit of _actual liars_.


> So how will people decide where to draw the line? My guess is: in a place drawn by bias and motivated reasoning, same way they decide everything else. The outgroup will be lying liars, and the ingroup will be decent people with ordinary human failings.
