## Maybe Lying Doesn't Exist

In ["Against Lie Inflation"](https://slatestarcodex.com/2019/07/16/against-lie-inflation/), the immortal Scott Alexander argues that the word "lie" should be reserved for knowingly-made false statements, and not used in an expanded sense that includes unconscious motivated reasoning. Alexander argues that the expanded sense draws the category boundaries of "lying" too widely in a way that would make the word less useful. The hypothesis that predicts everything predicts nothing: in order for "Kevin lied" to _mean something_, some possible states-of-affairs need to be identified as _not_ lying, so that the statement "Kevin lied" can correspond to [redistributing conserved probability mass](http://yudkowsky.net/rational/technical/) _away from_ "not lying" states-of-affairs _onto_ "lying" states-of-affairs.

All of this is entirely correct. But Jessica Taylor (whose post ["The AI Timelines Scam"](https://unstableontology.com/2019/07/11/the-ai-timelines-scam/) inspired "Against Lie Inflation") wasn't arguing that _everything_ is lying; she was just using a _more_ permissive conception of lying than the one Alexander prefers. Concerning Alexander's arguments against the expanded definition, I find I have one strong objection (that appeal-to-consequences is an invalid form of reasoning for optimal-categorization questions for the the same reason as it is for questions of simple fact), and one more speculative objection (that our intuitive "folk theory" of lying may actually be empirically mistaken). Let me explain.

(A small clarification: for myself, I _also_ tend to frown on the expanded sense. But the _reasons_ for frowning matter! People who superficially agree on a conclusion but for _different reasons_, are [not really on the same page](https://www.lesswrong.com/posts/n4ukoQzkgbAqpzqb5/argue-politics-with-your-best-friends)!)

### Appeals to Consequences Are Invalid

> There is no method of reasoning more common, and yet none more blameable, than, in philosophical disputes, to endeavour the refutation of any hypothesis, by a pretense of its dangerous consequences[.]
>
> —[David Hume](https://www.bartleby.com/37/3/12.html)

Alexander contrasts the imagined consequences of the expanded definition of "lying" becoming more widely accepted, to a world that uses the restricted definition:

> [E]veryone is much angrier. In the restricted-definition world, a few people write posts suggesting that there may be biases affecting the situation. In the expanded-definition world, those same people write posts accusing the other side of being liars perpetrating a fraud. I am willing to listen to people suggesting I might be biased, but if someone calls me a liar I'm going to be pretty angry and go into defensive mode. I'll be less likely to hear them out and adjust my beliefs, and more likely to try to attack them.

But this is an [appeal to consequences](https://en.wikipedia.org/wiki/Appeal_to_consequences). [Appeals to consequences](https://www.lesswrong.com/posts/P3FQNvnW8Cz42QBuA/dialogue-on-appeals-to-consequences) are invalid because they represent a map–territory confusion, an attempt to optimize our _description_ of reality at the expense of our ability to describe reality _accurately_ (which we need in order to _actually_ optimize reality).

(Again, the appeal is still invalid even if the conclusion—in this case, that unconscious rationalization shouldn't count as "lying"—might be true for _other reasons_.)

Some aspiring epistemic rationalists like to call this the ["Litany of Tarski"](https://wiki.lesswrong.com/wiki/Litany_of_Tarski). _If_ Elijah is lying (with respect to whatever the [optimal category boundary](https://www.lesswrong.com/posts/esRZaPXSHgWzyB2NL/where-to-draw-the-boundaries) for "lying" turns out to be according to [our standard Bayesian philosophy of language](https://www.lesswrong.com/posts/FaJaCgqBKphrDzDSj/37-ways-that-words-can-be-wrong)), _then_ I desire to believe that Elijah is lying (with respect to the optimal category boundary according to ... _&c._). _If_ Elijah is _not_ lying (with respect to ... _&c._), _then_ I desire to believe that Elijah is _not_ lying.

If the one comes to me and says, "Elijah is not lying; to support this claim, I offer this-and-such evidence of his sincerity," then this is right and proper, and I am eager to examine the evidence presented.

If the one comes to me and says, "You should choose to define _lying_ such that Elijah is not lying, because if you said that he was lying, then he might feel angry and defensive," this is _insane_. The map is not the territory! If Elijah's behavior is, _in fact_, deceptive—if he says things that cause people who trust him to be worse at [anticipating their experiences](https://www.lesswrong.com/posts/a7n8GdKiAZRX86T5A/making-beliefs-pay-rent-in-anticipated-experiences) when he [could](https://www.lesswrong.com/posts/3buXtNiSK8gcRLMSG/possibility-and-could-ness) have avoided this—I can't make his behavior not-deceptive by _changing the meanings of words_.

Now, I _agree_ that it might very well empirically be the case that if I _say_ that Elijah is lying (where Elijah can hear me), he might get angry and defensive, which could have a variety of negative social consequences. But that's not an argument for changing the definition of lying; that's an argument that I have an incentive to lie about whether I think Elijah is lying! (Though [Glomarizing](https://www.lesswrong.com/posts/xdwbX9pFEr7Pomaxv/meta-honesty-firming-up-honesty-around-its-edge-cases#1__Glomarization_can_t_practically_cover_many_cases_) about whether I think he's lying might be an even better play.)

Alexander is concerned that people might strategically equivocate between different definitions of "lying" as an unjust social attack against the innocent, using the classic [motte-and-bailey](https://slatestarcodex.com/2014/11/03/all-in-all-another-brick-in-the-motte/) maneuver: first, argue that someone is "lying (expanded definition)" (motte), then switch to treating them as if they were guilty of "lying (restricted definition)" (bailey) and hope no one notices.

So, I agree that [this is a very real problem](https://www.lesswrong.com/posts/shoMpaoZypfkXv84Y/variable-question-fallacies). But I don't think this is a valid argument against the expanded definition of "lying", because the problem of equivocation between [different category boundaries associated with the same word](https://www.lesswrong.com/posts/4FcxgdvdQP45D6Skg/disguised-queries) applies _symmetrically_: if it's possible to use an expanded definition of a socially-disapproved category as the motte and a restricted definition as the bailey in an unjust attack against the innocent, then it's _also_ possible to use an expanded definition as the bailey and a restricted definition as the motte in an unjust defense of the guilty.

Alexander writes:

> The whole reason that rebranding lesser sins as "lying" is tempting is because everyone knows "lying" refers to something very bad. 

Right—and conversely, because everyone knows that "lying" refers to something very bad, it's tempting to rebrand lies as lesser sins. Ruby Bloom [explains what this looks like in the wild](https://www.lesswrong.com/posts/QB9eXzzQWBhq9YuB8/rationalizing-and-sitting-bolt-upright-in-alarm#R9kEwAz8YbQTWGPsB):

> I worked in a workplace where lying was commonplace, conscious, and system 2. Clients asking if we could do something were told "yes, we've already got that feature (we hadn't) and we already have several clients successfully using that (we hadn't)." Others were invited to be part an "existing beta program" alongside others just like them (in fact, they would have been the very first). When I objected, I was told "no one wants to be the first, so you have to say that."
>
> [...] I think they lie to themselves that they're not lying (so that if you search their thoughts, they never think "I'm lying")[.]

If your interest in the philosophy of language is primarily to _avoid being blamed for things_—perhaps because you percieve that you live [in a Hobbesian dystopia](https://www.lesswrong.com/posts/YRgMCXMbkKBZgMz4M/asymmetric-justice#puGDkhWCcaNJEMkdz) where the primary function of words is to elicit actions, where the [denotative content](https://www.lesswrong.com/posts/i2bWqSFgyFxowTKWE/actors-and-scribes-words-and-deeds) of language has [decayed](https://www.lesswrong.com/posts/8XDZjfThxDxLvKWiM/excerpts-from-a-larger-discussion-about-simulacra) long ago, and all that's left is a [standardized list of approved attacks](https://www.lesswrong.com/posts/r2dTchodfqX4o5DYH/blame-games)—in that case, it makes perfect sense to worry about "lie inflation" but not about "lie deflation." If describing something as "lying" is primarily a weapon, then applying extra scrutiny to uses of that weapon is a prudent arms-restriction treaty.

But if your interest in the philosophy of language is to improve and refine the uniquely human power of [vibratory telepathy](https://www.lesswrong.com/posts/SXK87NgEPszhWkvQm/mundane-magic)—to construct shared maps that reflect the territory—if you're interested in revealing what kinds of deception are _actually happening_, and why—

(in short, if you are an aspiring epistemic rationalist)

—then the asymmetrical concern for false-positives identifications of "lying" but not false-negatives—along with the focus on "bad actors", "stigmatization", "attacks", _&c._—just looks _weird_. What does _that_ have to do with maximizing the probability you assign to the right answer??

### The Optimal Categorization Depends on the Actual Psychology of Deception

> _Deception_  
> _My life seems like it's nothing but_  
> _Deception_  
> _A big charade_  
>
> _I never meant to lie to you_  
> _I swear it_  
> _I never meant to play those games_
>
> —["Deception"](https://www.youtube.com/watch?v=kQKs0eQHZRs) by Jem and the Holograms




As [Ben Hoffman points out in the comments](https://slatestarcodex.com/2019/07/16/against-lie-inflation/#comment-777559), 


> Politicians lie, but not _too much_. Take the top story on Politifact Fact Check today. Some Republican claimed his supposedly-maverick Democratic opponent actually voted with Obama's economic policies 97 percent of the time. Fact Check explains that the statistic used was actually for all votes, not just economic votes, and that members of Congress typically have to have >90% agreement with their president because of the way partisan politics work. **So it's a lie, and is properly listed as one.** But it's a lie based on slightly misinterpreting a real statistic. He didn't just totally make up a number. He didn't even just make up something else, like "My opponent personally helped design most of Obama's legislation". [bolding mine —ZMD]


https://slatestarcodex.com/2014/05/12/weak-men-are-superweapons/


> [P]eople think in terms of categories with central and noncentral members–a sparrow is a central bird, an ostrich a noncentral one. But if you live on the Ostrich World, which is inhabited only by ostriches, emus, and cassowaries, then probably an ostrich seems like a pretty central example of 'bird' and the first sparrow you see will be fantastically strange.

What if we live in Ostrich World? I mean—what if unconscious lying is the central case?

https://www.lesswrong.com/posts/pZSpbxPrftSndTdSf/honesty-beyond-internal-truth


dissemble


[TODO: reference http://benjaminrosshoffman.com/authenticity-vs-factual-accuracy/
http://benjaminrosshoffman.com/blackmailers-are-privateers-in-the-war-on-hypocrisy/
]

Robert S. Feldman, James A. Forrest, and Benjamin R. Happ


https://mises.org/library/rothbards-left-and-right-forty-years-later

> Suppose I were to invent a new word, "zaxlebax," and define it as "a metallic sphere, like the Washington Monument." That's the definition—"a metallic sphere, like the Washington Monument." In short, I build my ill-chosen example into the definition. Now some linguistic subgroup might start using the term "zaxlebax" as though it just meant "metallic sphere," or as though it just meant "something of the same kind as the Washington Monument." And that's fine. But my definition incorporates both, and thus conceals the false assumption that the Washington Monument is a metallic sphere; any attempt to use the term "zaxlebax," meaning what I mean by it, involves the user in this false assumption.

