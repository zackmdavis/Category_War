# Meta-Honesty Is Useless Because Most Deception Does Not Take the Form of Conscious Unambiguous Explicit Lies

**Reply to**: [Meta-Honesty: Firming Up Honesty Around Its Edge-Cases](https://www.lesswrong.com/posts/xdwbX9pFEr7Pomaxv/meta-honesty-firming-up-honesty-around-its-edge-cases)

Eliezer Yudkowsky, listing advantages of a "wizard's oath" ethical code of "Don't say things that are literally false", writes—

> Most people, even most unusually honest people, wander about their lives in a fog of internal distortions of reality. Repeatedly asking yourself of every sentence you say aloud to another person, "Is this statement actually and literally true?", helps you build a skill for navigating out of your internal smog of not-quite-truths. For that is our mastery.

I mean, that's _one_ hypothesis about the psychological effects of adopting the wizard's code.

A potential problem is that human natural language contains a _lot_ of ambiguity. Words can be used in many ways depending on context. Even the specification "literally" in "literally false" is less useful than it initially appears when you consider that the way people _ordinarily_ speak when being truthful is actually pretty dense with metaphors that we typically don't _notice_ as metaphors because they're common enough to be recognized legitimate uses that all fluent speakers will understand.

For example, if I want to convey the meaning that our study group has covered a lot of material in today's session, and I say, "Look how far we've come today!" it would be _pretty weird_ if you were to object, "_Liar!_ We've been in this room the whole time and haven't physically moved at all!" because in this case, it really is obvious to all ordinary English speakers that that's not what I meant by "how far we've come."

Other times, the "intended" interpretation of a statement is not only not obvious, but speakers can mislead by motivatedly equivocating between different definitions of words:[^intended] the immortal Scott Alexander has written a lot about this phenomenon under the labels ["motte-and-bailey doctrine"](https://slatestarcodex.com/2014/11/03/all-in-all-another-brick-in-the-motte/) (as [coined by Nicholas Shackel](https://philpapers.org/archive/SHATVO-2.pdf)) and ["the noncentral fallacy"](https://www.lesswrong.com/posts/yCWPkLi8wJvewPbEp/the-noncentral-fallacy-the-worst-argument-in-the-world).

[^intended]: I'm scare-quoting "intended" because this process usually isn't conscious. Internal distortions of reality in [imperfectly deceptive social organisms](https://intelligence.org/files/CFAI.pdf#page=48) can be [adaptive for the function of deceiving conspecifics](https://www.lesswrong.com/posts/DSnamjnW7Ad8vEEKd/trivers-on-self-deception).

So the question "Is this statement actually and literally true?" is itself potentially ambiguous. It could mean either—

 * "Is this statement actually and literally true _as the audience will interpet it?_"; or,
 * "Does this statement _permit an interpretation under which_ it is actually and literally true?"

But while the former is complicated and hard to establish, the latter is ... _really just not that strict of a constraint_.

Think about it. When's the last time you needed to consciously tell a bald-faced, _unambiguous_ lie?—something that could realistically be _outright proven false_ in front of your peers, rather than dismissed with a "reasonable" amount of language-lawyering. (For example, if you said you've never stepped foot in Albuquerque, everyone would agree that this would be falsified by a (non-doctored) photo of you in Albuquerque, because "never stepped foot in" doesn't leave very much linguistic wiggle room. But if you said you were "Fine" when I asked how you were, and actually you were a little bit sad, one could argue that it's not 

Maybe I'm _unusually_ honest—or possibly unusually bad at remembering when I've lied?—but I'm not sure I even _remember_ the last time I told an outright lie. The situation just _doesn't come up that often_.

Okay, now 



So another hypothesis is that the wizard's oath just ends up with you training yourself to get _really good_ at misleading people with a variety of [not-technically-lying](https://www.lesswrong.com/posts/PrXR66hQcaJXsgWsa/not-technically-lying) rhetorical tactics (motte-and-baileys, false [implicatures](https://plato.stanford.edu/entries/implicature/), evasions, [selective reporting](https://www.lesswrong.com/posts/esRZaPXSHgWzyB2NL/where-to-draw-the-boundaries), ["clever" rationalized arguments](https://www.lesswrong.com/posts/9f5EXt8KNNxTAihtZ/a-rational-argument), [gerrymandered category boundaries](https://www.lesswrong.com/posts/esRZaPXSHgWzyB2NL/where-to-draw-the-boundaries), _&c._), all the while congratulating yourself on how honest you are for not making "literally" "false" individual statements.


-----

When's the last time you had motives to optimize your communication for having some affect on people other than causing them to have more accurate anticipations of experience? _Every fucking time you open your mouth_, that's when.

Suppose I see someone wearing a red shirt stealing from the cookie jar. Carol often wears red [maybe not the best example]

I will grant that not-lying has the advantage of being a bright line rather than a messy border

on the other hand, you don't want to be exploitable by motivated misunderstandings

a topical example: OpenAI's Rubik's cube, Greg Brockman

Katja Grace on "principles are for bargaining"

disambiguate what I'm saying from "If we can't lie to others, we will lie to ourselves"

by "God" I just mean the order and beauty in the universe

Everybody knows that

Atlas Shrugged State Science Institute
