## There's No Such Thing as Unmotivated Reasoning

Traditional rationalists have a concept of ["motivated reasoning"](https://en.wikipedia.org/wiki/Motivated_reasoning) as a sin, and, often, the further idea that [you also shouldn't _accuse_ others of motivated reasoning](https://slatestarcodex.com/2019/07/17/caution-on-bias-arguments/).

These social rules are very effective at inducing humans to reason better! If you've been taught that "motivated reasoning" is bad, you're more likely to notice when you're [selectively attending to evidence and arguments](https://www.lesswrong.com/posts/9f5EXt8KNNxTAihtZ/a-rational-argument) that favor a conclusion you [already prefer for different reasons](https://www.lesswrong.com/posts/TGux5Fhcd7GmTfNGC/is-that-your-true-rejection). And if you've been taught not to accuse _other_ people of motivated reasoning but instead to engage with their actual arguments, that protects you from the failure mode of dismissing all evidence and arguments that contradict [your favored conclusion](https://www.lesswrong.com/posts/34XxbRFe54FycoCDw/the-bottom-line) on the grounds that [the _other_ guy is biased](https://www.lesswrong.com/posts/AdYdLP2sRqPMoe8fb/knowing-about-biases-can-hurt-people).

It's ironic that, as effective and essential as this advice is for humans, it's actually founded on a falsehood! Technically, there's no such thing as _un_-motivated reasoning. There's [no ideal philosopher-ghost of perfect emptiness](https://www.lesswrong.com/posts/qmqLxvtsPzZ2s6mpY/a-priori) that can somehow produce correct maps _without trying to do anything_.

Our paradigmatic example of motivated reasoning is the political partisan: consider a fanatical adherent to the Green faction [in a Society polarized between Blue and Green camps on issues of tax policy, divorce law, and the color of the sky](https://www.lesswrong.com/posts/6hfGNLf4Hg5DXqJCF/a-fable-of-science-and-politics). Our partisan [never _lies_ about matters of fact](https://www.lesswrong.com/posts/MN4NRkMw7ggt9587K/firming-up-not-lying-around-its-edge-cases-is-less-broadly)—certainly not! Rather, he just reads everything he can about why the sky is green, why merchant taxes and no-fault divorce are the best policies, and why the greedy, hate-filled Blues who think otherwise are lying liars who hate children, reality, and themselves.

If you try to engage him on the merits of income taxes, or covenant marriage, or whether the sky might actually be blue, and you manage to make some surprisingly good points he doesn't already have [cached](TODO: linky "Cached Thoughts") rebuttals to, then he'll equivocate, [stonewall](TODO: linky "Conversation Halters"), change the subject--anything to _stay in control of the conversation_, and steer it where he wants it to go: to support the Greens.

Now consider a seemingly very different kind of interlocutor—a child, probably autistic, with a special interest in trains, who reads everything he can about trains: [TODO: train facts]. If you try to engage him on the merits of any topic that isn't about trains, then he'll equivocate, stonewall, change the subject--anything to _stay in control of the conversation_, and steer it where he wants it to go: to be about trains.

Traditional rationalists think of the political partisan as the exemplar of "motivated reasoning", and not the train enthusiast, who we would just say is very ... specialized. But if you [replace the specific content with gensyms](TODO: linky "Truly Part of You"), their behavior is actually very similar! What's going on here? Is there some general framework we can use to make sense of this?


----

Outline—
* The optimizer can be causally upstream of the person who actually produced the text

https://www.lesswrong.com/posts/PtoQdG7E8MxYJrigu/no-universally-compelling-arguments

https://www.lesswrong.com/posts/KZLa74SzyKhSJ3M55/the-genetic-fallacy
> Once an idea gets into your head, you tend to find support for it everywhere you look
> if the causes of a belief do not determine its systematic reliability, what does?
