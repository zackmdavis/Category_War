
with an $O(log n)$ binary search-like procedure

an $O(n)$ linear search


I'm _not_ talking about the problem of pressure on your beliefs

For example, if you said you've never stepped foot in Albuquerque, everyone would agree that this would be falsified by a (non-doctored) photo of you in Albuquerque, because "never stepped foot in" doesn't leave very much linguistic wiggle room.

But if you said you were "Fine" when I asked how you were, and actually you were a little bit sad, one could argue that it's not [...]


When's the last time you had motives to optimize your communication for having some affect on people other than causing them to have more accurate anticipations of experience? _Every fucking time you open your mouth_, that's when.

Suppose I see someone wearing a red shirt stealing from the cookie jar. Carol often wears red [maybe not the best example]

I will grant that not-lying has the advantage of being a bright line rather than a messy border

Bayesian 

on the other hand, you don't want to be exploitable by motivated misunderstandings

a topical example: OpenAI's Rubik's cube, Greg Brockman

Katja Grace on "principles are for bargaining"

disambiguate what I'm saying from "If we can't lie to others, we will lie to ourselves"

by "God" I just mean the order and beauty in the universe

Everybody knows that (lightning)

Atlas Shrugged State Science Institute

---------

Unilateralist's Blessing https://www.lesswrong.com/posts/8xomBzAcwZ6WTC8QB/steven0461-s-shortform-feed-1#P4J5jB3kmhFXMuRrM

, then authors would be faced with a tough choice:

[TODO: address stabilizing Schelling point objection]  
[TODO: maybe everyone _should_ be angrier, if lies are actualy that common and anger is a functional response?]  
[TODO: acknowledge that Alexander must know that the reason to "prefer" a category is _because_ it affects anticipations—"its web of connotations in our minds"]

https://www.lesswrong.com/posts/9QxnfMYccz9QRgZ5z/the-costly-coordination-mechanism-of-common-knowledge

ingroup/outgroup

(If you're reading this blog, this should not be a new idea to you!)

Ostrich World

This view is making some implicit assumptions about human psychology: 


As [Ben Hoffman points out in the comments](https://slatestarcodex.com/2019/07/16/against-lie-inflation/#comment-777559), 


> Politicians lie, but not _too much_. Take the top story on Politifact Fact Check today. Some Republican claimed his supposedly-maverick Democratic opponent actually voted with Obama's economic policies 97 percent of the time. Fact Check explains that the statistic used was actually for all votes, not just economic votes, and that members of Congress typically have to have >90% agreement with their president because of the way partisan politics work. **So it's a lie, and is properly listed as one.** But it's a lie based on slightly misinterpreting a real statistic. He didn't just totally make up a number. He didn't even just make up something else, like "My opponent personally helped design most of Obama's legislation". [bolding mine —ZMD]


https://slatestarcodex.com/2014/05/12/weak-men-are-superweapons/


> [P]eople think in terms of categories with central and noncentral members–a sparrow is a central bird, an ostrich a noncentral one. But if you live on the Ostrich World, which is inhabited only by ostriches, emus, and cassowaries, then probably an ostrich seems like a pretty central example of 'bird' and the first sparrow you see will be fantastically strange.

What if we live in Ostrich World? I mean—what if unconscious lying is the central case?

https://www.lesswrong.com/posts/pZSpbxPrftSndTdSf/honesty-beyond-internal-truth


dissemble


[TODO: reference http://benjaminrosshoffman.com/authenticity-vs-factual-accuracy/
http://benjaminrosshoffman.com/blackmailers-are-privateers-in-the-war-on-hypocrisy/
https://www.lesswrong.com/posts/bwkZD6uskCQBJDCeC/self-consciousness-wants-to-make-everything-about-itself
https://everythingstudies.com/2019/08/19/the-prince-and-the-figurehead/


https://slatestarcodex.com/2014/11/05/the-right-to-waive-your-rights/
https://slatestarcodex.com/2018/03/22/navigating-and-or-avoiding-the-inpatient-mental-health-system/
]

Robert S. Feldman, James A. Forrest, and Benjamin R. Happ




> Suppose I were to invent a new word, "zaxlebax," and define it as "a metallic sphere, like the Washington Monument." That's the definition—"a metallic sphere, like the Washington Monument." In short, I build my ill-chosen example into the definition. Now some linguistic subgroup might start using the term "zaxlebax" as though it just meant "metallic sphere," or as though it just meant "something of the same kind as the Washington Monument." And that's fine. But my definition incorporates both, and thus conceals the false assumption that the Washington Monument is a metallic sphere; any attempt to use the term "zaxlebax," meaning what I mean by it, involves the user in this false assumption.


----

DRAFT: "Maybe Lying Doesn't Exist"

Attention conservation notice: this is _not_ a "privileged" meeting of the Blight-alarmist coordination group (if that's a thing); this is just me personally sending _my_ blog post draft to a few people who I still happen to have outgoing-mail privileges with, for them to _probably_ ignore as they see fit.

Scott is too famous and too traumatized to do any real thinking these days, but the audience might learn something?

Writing the "Appeals to Consequences Are Invalid" section made me feel less angry at Scott over our earlier dispute, because I'm now leaning towards the hypothesis that he's _not_ opporunistically switching philosophy stances because throwing me under the bus helped him stay out of [Overton debt](https://www.lesswrong.com/posts/DoPo4PDjgSySquHX8/heads-i-win-tails-never-heard-of-her-or-selective-reporting)! He _actually doesn't get it_. He's _actually that dumb!_ (Trauma-induced dumb, not _g_-factor dumb.)

Hopefully the second section helps clarify the state of my persistent disagreement with the other Blight-alarmists on the lie/scam/fraud issue??

I originally went for "Appeals to Consequences Are Insane", but I'm going with "Invalid" as a strategic concession to the target audience, who will write me off as too "mean" if I say _insane_ in the section title. (One use of _insane_ survives in the text.)

Is it bad (is it lying??) if the title is kind of clickbaity? (Outrageous four-word summary incentivizes a click, but then the actual post is less outrageous.) Not sure what else I would call it.




> (in short, if you are an aspiring epistemic rationalist)

Author's note: this originally just read "if you are a rationalist", but 

---

Jessica explaining talking about conflict: https://www.greaterwrong.com/posts/9fB4gvoooNYa4t56S/power-buys-you-distance-from-the-crime/comment/S4QephDXJWqGJhuuH


----


[TODO: elaborate and explain that `reporter_2` at least _comes closer_ than reporter_1; the output still varies with reality; it's just distorted; whereas the liar was constant]

"Maybe Lying ..."

Three Algorithms of Deception

'My basic read of Zack's entire post was him saying over and over "Well there might be really bad instrumental effects of these arguments, but you have to ignore that if their epistemics are good." And my immediate reaction to that was "No I don't, and that's a bad norm."'

x₁

(I originally imagined this with normal distributions with different means, but choosing a discrete distribution makes explicit calculations easier, and it doesn't matter for the point I'm trying to make.)

ask mods whether it's possible to upload to images.lesswrong.com

[TODO: use "typical set" reasoning to show that these are distinct clusters
https://en.wikipedia.org/wiki/Asymptotic_equipartition_property
http://zackmdavis.net/blog/2019/05/the-typical-set/
]

[Leaky Generalizations](https://www.lesswrong.com/posts/Tc2H9KbKRjuDJ3WSS/leaky-generalizations)

Make sure to mention that clustering is hard—
http://alexhwilliams.info/itsneuronalblog/2015/09/11/clustering1/
http://alexhwilliams.info/itsneuronalblog/2015/10/01/clustering2/

Goodhart's Law: https://www.lesswrong.com/posts/EbFABnst8LsidYs5Y/goodhart-taxonomy regressional Goodhart

the intelligence, wisdom, maturity, civic-mindedness, perhaps motor skills (to fill in the ballot), _&c._ needed to exercise the franchise responsibly.

[important for game-theoretic reasons](https://www.lesswrong.com/posts/tJQsxD34maYw2g5E4/thomas-c-schelling-s-strategy-of-conflict#yqGXfQpsDuEGeL69a)

-------

_Author's Note on Contextualizing and the Development of Ideas_

[TODO: maybe a separate post???]

MacIver's book rec: https://twitter.com/DRMacIver/status/1139839288202297345

Imgur post: https://imgur.com/a/yjzfM9H

-------

Consider again the parable about the Sorter of bleggs and rubes who is at first overjoyed to be promoted to "Vice President of Sorting", only to be dismayed to learn that the change in title doesn't come with any material change in responsibilities or working conditions.

Is the new title a _lie_? I think many people would be inclined to say _No_, on the grounds that they expect 

[This](http://benjaminrosshoffman.com/excerpts-from-a-larger-discussion-about-simulacra/) may constitute a "security vulnerability" in [codes of ethics](https://www.lesswrong.com/posts/xdwbX9pFEr7Pomaxv/meta-honesty-firming-up-honesty-around-its-edge-cases) that have an [ethical injunction](https://www.lesswrong.com/posts/dWTEtgBfFaz6vjwQf/ethical-injunctions) against lying.


blue                   green
urban                  rural
indidividual taxes     merchant tax
strict marriage        easy divorce
Earth-centered         heliocenteric




An [evolutionary psychologist](TODO: linky) studying pair bonding may aspire to objectivity, but if she finds that

The Blues believe the Earth is a sphere at the center of the universe; the Greens believe the Earth is a plane that revolves around a sun.

https://slatestarcodex.com/2017/03/24/guided-by-the-beauty-of-our-weapons/
https://slatestarcodex.com/2013/12/29/the-spirit-of-the-first-amendment/

I'm usually an "Inside View" kind of guy, but _principles_ are an Outside View thing!

contrast—
https://twitter.com/ESYudkowsky/status/1170022426891018240
https://www.lesswrong.com/posts/k5qPoHFgjyxtvYsm7/stop-voting-for-nincompoops

if one side has all the brains

https://www.lesswrong.com/rationality/how-much-evidence-does-it-take

"Tails Risk"

the meta-hill is a Schelling point for dying on

What makes paying rent to the coalition bad, but having an obsessive special interest OK?

So, sure, I'd lie to a Nazi at my door asking me if I'm hiding any Jews. (Or about, um, being Jewish.) I also recommend lying to psychiatrists (who face incentives to [throw you in prison for 5.9 days](https://slatestarcodex.com/2018/03/22/navigating-and-or-avoiding-the-inpatient-mental-health-system/) in order to ensure [they don't get personally blamed for anything](https://slatestarcodex.com/2014/11/05/the-right-to-waive-your-rights/)).

> No exit—her shreds of awareness were saying, beating it into the pavements in the sound of her steps—no exit ... no refuge ... no signals ... no way to tell destruction from safety, or enemy from friend. ... Like that dog she had heard about, she thought ... somebody's dog in somebody's laboratory ... the dog who got his signals switched on him, and saw no way to tell satisfaction from torture, saw food changed to beatings and beatings to food, saw his eyes and ears deceiving him and his judgement futile and his consciousness impotent in a shifting, swimming, shapeless world—and gave up, refusing to eat at that price or live in a world of that kind. No!—was the only conscious word in her brain—no!—no!—no!—not your way, not your world—even if this "no" is all that's to be left of mine!
>
> —_Atlas Shrugged_ by Ayn Rand

Said on graphs: https://www.lesswrong.com/posts/y4bkJTtG3s5d6v36k/stupidity-and-dishonesty-explain-each-other-away?commentId=zcBFbHL2azWBSa4kY

Imgur post: https://imgur.com/a/aTcjknM

The answer is that we can apply our criteria for optimization, looking for theories that predict observed behavior that can be [specified using fewer bits](https://www.lesswrong.com/posts/f4txACqDWithRi7hs/occam-s-razor) by "looking backwards" from what goals the behavior achieves, rather than "looking forward" at the psychological mechanisms computing the behavior, which, in the absence [(as far as I know)](https://www.lesswrong.com/posts/vNBxmcHpnozjrJnJP/no-one-knows-what-science-doesn-t-know) of sufficiently advanced cognitive neuroscience, we can mostly only understand by the ["empathic inference"](https://www.lesswrong.com/posts/9fpWoXpNv83BAHJdc/the-comedy-of-behaviorism) of imagining what we would do if we were the subject, using our own brain as a "black box" to predict others. [TODO: simplify!!]


> among other things, the true referent of "consciousness" is also the cause in humans of talking about inner listeners.


https://www.lesswrong.com/posts/JoERzF8ePGr4zP9vv/self-deception-hypocrisy-or-akrasia


[conscious and unconscious fraud are different—but another agent who's dealing with you may wish to regard this as the difference between mergesort and quicksort]

https://www.lesswrong.com/posts/28bAMAxhoX3bwbAKC/are-your-enemies-innately-evil

https://sideways-view.com/2016/11/26/if-you-cant-lie-to-others-you-must-lie-to-yourself/

explain how: https://www.lesswrong.com/posts/Mc6QcrsbH5NRXbCRX/dissolving-the-question
why do I _think_ the question is right: https://www.lesswrong.com/posts/rQEwySCcLtdKHkrHp/righting-a-wrong-question


> The bureaucrat, police officer, teacher, judge, or cable television company representative functions as [...], not as a co-modeling and fully interacting person. His behaviors are governed by top-down rules and scripts, with human discretion eliminated as much as possible.
>
> Sarah Perry, "The Essence of Peopling"

pretending to be stupid: https://slatestarcodex.com/2014/08/14/beware-isolated-demands-for-rigor/

also address: machine learning, deception in nature—it's _really convenient_ to use the "learning" and "deception" codewords, and there's no convenient replacement—maybe that suggests that they are the right words

https://www.greaterwrong.com/posts/DSnamjnW7Ad8vEEKd/trivers-on-self-deception/comment/CandwLBdJXXq7Qxet


not satisfied with quasi- https://www.lesswrong.com/posts/FT9Lkoyd5DcCoPMYQ/partial-summary-of-debate-with-benquo-and-jessicata-pt-1?commentId=coWFfoYqdeuSPpTqe#vPekZcouSruiCco3c

[can crimes be discussed literally
https://www.lesswrong.com/posts/N9oKuQKuf7yvCCtfq/can-crimes-be-discussed-literally ]

> "Accuse me of _fraud_? How _dare_ you?! Sure, I'm not a perfect person free from all bias, but—"
>
> "Bias. Is that your word for 'having a disposition to communicate in a way that causes others to make incorrect predictions about the value you have to offer, in a direction that moves resources towards you'?"
>
> "Uh. I guess you could say that."
>
> "What do you think 'fraud' _is_, exactly?"

----

There's no rule of rationality against _lying_.

https://arbital.greaterwrong.com/p/executable_philosophy?l=112

what that _means_ is that (at some appropriate level of abstraction) there's a little [Bayesian network](https://www.lesswrong.com/posts/hzuSDMx7pd2uxFc5w/causal-diagrams-and-causal-models) in my head with "blueness" and "eggness" observation nodes hooked up to a central "blegg" category-membership node, such that if I see a black-and-white photograph of an egg-shaped object, I can use the observation of its shape to update my beliefs about its blegg-category-membership, and then use my beliefs about category-membership to update my beliefs about its blueness. This cognitive algorithm is useful if we live in a world where objects that have the appropriate statistical structure—if the joint distribution P(blegg, blueness, eggness) approximately factorizes as P(blegg)·P(blueness|blegg)·P(eggness|blegg).


"Category boundaries" are just a _visual metaphor_ for the math: the set of things I'll classify as a blegg with probability greater than _p_ is conveniently _visualized_ as an area with a boundary in blueness–eggness space. If you _don't understand_ the relevant math and philosophy—or are pretending not to understand only and exactly when it's politically convenient—you might think you can redraw the boundary any way you want, but you can't, because the "boundary" visualization is _derived from_ a statistical model which corresponds to _empirically testable predictions about the real world_. Fucking with category boundaries corresponds to fucking with the model, which corresponds to fucking with your ability to interpret sensory data.

 The only two reasons you could _possibly_ want to do this would be to wirehead yourself (corrupt your map to make the territory look nicer than it really is, making yourself _feel_ happier at the cost of sabotaging your ability to navigate the real world) or as information warfare (corrupt shared maps to sabotage other agents' ability to navigate the real world, in a way such that you benefit from their confusion).

https://getpocket.com/explore/item/is-lab-grown-meat-really-meat

utility of certainty

(not even one unit of epistemology, I feel like my epistemology will let me make exactly as good predictions as yours will about any [...] in the vicinity)

> You _can_ define a word any way you want, you just have to pay the costs [later, when saying you can still do Bayesian inference on the gerrymandered category]


But if another system _does_ need to make inferences about an object's features, 



https://www.lesswrong.com/posts/WBw8dDkAWohFjWQSk/the-cluster-structure-of-thingspace

Suppose there's a robot arm in the Sorting room that puts bleggs in the blegg bin, which gets taken to the vanadium-ore processing room, where a more sophisticated  vanadium-ore processing machinery elsewhere in the factory that needs to handle both bleggs and gretrahedrons.

The ore-processor's models might be different from the three-feature models we used to _identify_ bleggs in the Sorting room—maybe it needs to vary its drill speed in proportion to the density of a particular blegg's flexible outer material.


Maybe the robot arm that puts bleggs in the blegg bin doesn't need to _know_ about the blueness and eggness scores: it can close its claws around rubes and bleggs alike, and you only need to program it to drop an object into the correct bin when told that the object "is a blegg" or "is a rube".

But if other machines in the factory need to do something more complicated—if they need to make _further inferences_ about something already known to be in the "vanadium-ore-containing blue eggs" cluster, it's a more efficient communication protocol to 


is a _specific mathematical model_ that makes _specific_ (probabilistic) predictions. What it _means_ is that if we see a black-and-white photo of an egg-shaped object (specifically, one with an eggness score of 7)

Scott on "voluntary"




 do cognitive work concerning our sortable objects, category labels can be used as signals to link up the models between different systems. Suppose there's some delicate vanadium-ore processing machinery elsewhere in the factory that needs to handle both bleggs and gretrahedrons. You want to be able to send commands to that machine, telling it to process a `BLEGG` using its _own_ models, _without_ having to

send over all the binary code of the Bayesian network and feature extractors that we used to identify the blegg.

The ore-processor's models might be different from the three-feature models we used to identify bleggs in the Sorting room—maybe it needs to vary its drill speed in proportion to the density of a particular blegg's flexible outer material.

[another diagram about using a signal to link up different models]

[there are more facts about bleggs than just three]

https://www.foodsafety.gov/food-safety-charts/safe-minimum-cooking-temperature

https://www.greaterwrong.com/users/zack_m_davis?offset=360

[argument from common usage]

For these reasons [it is written of the third virtue of lightness](https://yudkowsky.net/rational/virtues/): you _cannot_ make a true map of the category by drawing lines upon paper according to impulse; you must observe the joint distribution and draw lines on paper that correspond to what you see. If, seeing the category unclearly, you think that you can shift a line just a little to the right, just a little to the left, according to your caprice, this is just the same mistake.

As it is written of the tenth virtue of precision, even if you cannot do the math, knowing that the math exists tells you that the dance step is precise and has no room in it for your whims.

And as it is written of a virtue which is nameless: perhaps your conception of rationality is that it is rational to believe the words of the Great Teacher, and the Great Teacher says, "[]," and you look up at the sky and see blue.

If you think: "It may look like the sky is blue, such that I'd ordinarily think that someone who said 'The sky is green' was being deceptive. But surely the Great Teacher wouldn't tell blantant lies about his own philosophy of language for political convenience," you lose a chance to discover your mistake.

How will you discover your mistake? Not by comparing your description to itself.

But by comparing it to that which you did not name.

"But she still did it because she valued that choice above others—because of the feeling of importance she attached to that decision."
https://www.lesswrong.com/posts/n5ucT5ZbPdhfGNLtP/terminal-values-and-instrumental-values


[TODO Example: wireheading—believing I'm attractive]

[TODO Discuss Fallis and Lewis's criterion of deception having to benefit the deciever, because that explains why it would be systematic]

[TODO Example: butterfly mimickry]

[TODO Example: is artificial meat "real meat"]
