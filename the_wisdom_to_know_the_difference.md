## And the Wisdom to Know the Difference

The Regional Planning Commission is considering building an aqueduct at Jackson Point.

This is wrong. You _know_ this is wrong.

As usual, the simulation of a hypothetical adversary you keep running in your head has objections. _How_ do you you know this is wrong? it asks. What does it even _mean_ for something to be ["wrong"](https://www.lesswrong.com/posts/zqwWicCLNBSA5Ssmn/by-which-it-may-be-judged) [in a deterministic physical universe](https://www.lesswrong.com/posts/NEeW7eSXThPz7o4Ne/thou-art-physics)?

The adversary is usually smarter than this. You know the Regional Planning Commission is wrong because you have a detailed mental model of your Society and the physical world and the [Great Web of Causality](https://www.lesswrong.com/posts/2jp98zdLo898qExrr/hug-the-query) comprising them.

The model makes probabilistic predictions, but more than that, it makes _conditional_ probabilistic predictions. _If_ the aqueduct is built, you project a distribution of consequences (the additional water available to Jacksontown starting at Date, the money drawn from the Regional Planning budget, workers injured on the project, _&c._). _If_ the aqueduct is not built, then all will remain as it has been. You can _see_ the spread of possible worlds, you _have_ the correct social wefare function, and—even given the uncertainties about the site at Jackson Point—you know _it's not worth it_. You can't print out the full model in your head, but if you had to summarize it as an [influence diagram](https://en.wikipedia.org/wiki/Influence_diagram), it would look like this—

[diagram]

The rectangle represents the Commission's decision—a rectangle of _choice_, whose value has yet to be computed. The ovals represent uncertainties in the world. The diamond represents the sweet Utility of social welfare. Arrows to ovals hold a conditional probability table, yielding a probability distribution over the possible values of the node given the values of its parents. Arrows to the diamond hold a utility function. A simple calculation 

You have to act!—to _end_ this vile aqueduct scheme! You begin writing a post for your blog carefully explaining why the aqueduct is bad.

The hypothetical adversary is still running. Why is the Commission's decision a rectangle in your diagram? it asks.

You should probably invest in a smarter adversary. Because, you explain, it is a _decision_. [That's how decisionmaking works](https://www.lesswrong.com/posts/EsMhFZuycZorZNRF5/the-ultimate-source): in order to decide what decision to output, you make _conditional_ predictions for various things you [could](https://www.lesswrong.com/posts/3buXtNiSK8gcRLMSG/possibility-and-could-ness) do


No, I got that part, says the adversary. I meant, Why is the Commission's decision a rectangle in _your_ diagram?

[the commission's decision should be an oval with respect to the protagonist's graph ... the protagonist wonders what his oval looks like with respect to the adversary]
